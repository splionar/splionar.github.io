<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Stefan Lionar</title>

  <meta name="author" content="Stefan Lionar">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  
</head>

<body>
  <table
    style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:68%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Stefan Lionar</name>
                        <p style="text-align:justify">
                          I am a PhD student in Computer Science at the 
                          <a href="https://www.comp.nus.edu.sg/">National University of Singapore (NUS)</a>, 
                          supervised by <a href="https://www.comp.nus.edu.sg/~leegh/">Prof. Gim Hee Lee</a> and under the Industrial PhD Programme with <a href="https://www.garena.sg/">Garena</a> and 
                          <a href="https://sail.sea.com/">Sea AI Lab</a>. 
                          My work focuses on creating realistic 3D digital worlds and embodied agents that interact within them. I obtained my Master’s degree in Robotics from 
                          <a href="https://ethz.ch/en.html">ETH Zurich</a>, 
                          and Bachelor’s degree in Mechanical Engineering from 
                          <a href="https://www.ntu.edu.sg/">Nanyang Technological University</a>.
                        </p>


                  <p style="text-align:center">
                    <a href="mailto:splionar@gmail.com">Email</a> &nbsp/&nbsp
                    <a href="https://github.com/splionar">GitHub</a> &nbsp/&nbsp
                    <a href="https://scholar.google.com/citations?user=w6RfcvMAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                    <a href="https://openreview.net/profile?id=~Stefan_Lionar1">OpenReview</a> 
                  </p>

                </td>
                <!--td style="padding:2.5%;width:20%;max-width:40%">
                  <a href="images/profile_xxy.jpg"><img style="width:100%;max-width:100%" alt="profile photo"
                      src="images/profile_xxy.jpg" class="hoverZoomLink"></a>
                </td-->
              </tr>
            </tbody>
          </table>



                    <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>News</heading>
                  <ul>
                  <li>
                     <strong>[10.2025]</strong> Selected as a  <a href= https://neurips.cc/Conferences/2025/ProgramCommittee>top reviewer</a> (top 8%) at NeurIPS 2025!
                  </li>
                  <li>
                    <strong>[08.2025]</strong> Received my second <a href=https://www.comp.nus.edu.sg/programmes/pg/awards/deans-research>Research Achievement Award</a> from NUS School of Computing!
                  </li>
                  <li>
                     <strong>[02.2025]</strong> <a href="https://github.com/sail-sg/TreeMeshGPT">TreeMeshGPT</a> is accepted to CVPR 2025!
                  </li>
                  <li>
                    <strong>[01.2024]</strong> Received <a href=https://www.comp.nus.edu.sg/programmes/pg/awards/deans-research>Research Achievement Award</a> from NUS School of Computing!
                  </li>
                  <li>
                    <strong>[09.2023]</strong> <a href="https://numcc.github.io/">NU-MCC</a> is accepted to NeurIPS 2023!
                  </li>
                  <li>
                    <strong>[01.2023]</strong>  Started my PhD study at NUS.
                  </li>
                  <li>
                     <strong>[10.2021]</strong> My master's thesis (<a href="https://github.com/ethz-asl/neuralblox">NeuralBlox</a>) is accepted to 3DV 2021!
                  </li>
                  <li>
                     <strong>[11.2020]</strong> Our <a href="https://github.com/dsvilarkovic/dynamic_plane_convolutional_onet">3D vision course project</a> is accepted to WACV 2021!
                  </li>
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>



          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Publications</heading>
                  
                </td>
              </tr>
            </tbody>
          </table>


          <table
            style="width:100%;border:1px;border-spacing:1px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>



              <!-- TeamHOI -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div>
                    <!-- <div class="two" id='tog23sewformer_image'>
                      <img src='images/tog23sewformer_after.mp4' width="160">
                    </div> -->
                  <!-- Video demo -->

              <video width="200" height="auto" autoplay muted loop playsinline style="display:block;">
                <source src="video/teamhoi.mp4" type="video/mp4">
              </video>
                  </div>
                </td>
                <td width="90%" valign="middle">
                  <a href="https://splionar.github.io/">
                    <papertitle>TeamHOI: Learning a Unified Policy for Cooperative Human-Object Interactions with Any Team Size</papertitle>
                  </a>
                  <br>
                  <strong>Stefan Lionar</strong>, <a href="https://www.comp.nus.edu.sg/~leegh/">Gim Hee Lee</a>
                  <br>
                  <em></em>
                  <br>
                  <p>A novel framework for scalable cooperative human-object interaction.</p>
                </td>
              </tr>

              <!-- CVPR TreeMeshGPT -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div>
                    <!-- <div class="two" id='tog23sewformer_image'>
                      <img src='images/tog23sewformer_after.mp4' width="160">
                    </div> -->
                    <img src='images/tmgpt.png' width="200">
                  </div>
                </td>
                <td width="90%" valign="middle">
                  <a href="https://github.com/sail-sg/TreeMeshGPT/">
                    <papertitle>TreeMeshGPT: Artistic Mesh Generation with Autoregressive Tree Sequencing</papertitle>
                  </a>
                  <br>
                  <strong>Stefan Lionar</strong>, <a href="https://jiabinliang.github.io/">Jiabin Liang</a>, <a href="https://www.comp.nus.edu.sg/~leegh/">Gim Hee Lee</a>
                  <br>
                  <em>Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2025
                  <br>
                  <a href="https://arxiv.org/abs/2503.11629">Paper</a>
                  /
                  <a href="https://github.com/sail-sg/TreeMeshGPT">Code</a> <a class="more-link" href="https://github.com/sail-sg/TreeMeshGPT" target="_blank"><img alt="GitHub stars" align="right"
                    src="https://img.shields.io/github/stars/sail-sg/TreeMeshGPT?style=social"></a>
                  /
                  <a href="https://colab.research.google.com/drive/1UuYwl_GzkVmvcSReyqueMpOIsqr2u3cG?usp=sharing">Demo</a>

                  /
                  <a href="https://www.youtube.com/watch?v=9lOJ-V-K2O4&t=1s">Video</a>
                  <p>An autoregressive artistic mesh generation method that retrieves the next token from a dynamically growing tree structure. It achieves a state-of-the-art compression rate.</p>
                </td>
              </tr>
             

            <!-- NIPS23 NUMCC -->
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">

              <video width="200" height="auto" autoplay muted loop playsinline style="display:block;">
                <source src="video/numcc.mp4" type="video/mp4">
              </video>

              </td>

              <td width="90%" valign="middle">
                <a href="https://arxiv.org/abs/2307.09112">
                  <papertitle>NU-MCC: Multiview Compressive Coding with Neighborhood Decoder and Repulsive UDF</papertitle>
                </a>
                <br>
                <strong>Stefan Lionar</strong>,  <a href="https://xuxy09.github.io/">Xiangyu Xu<sup>&#x2709</sup></a>, <a href="https://linmin.me/">Min Lin</a>, <a href="https://www.comp.nus.edu.sg/~leegh/">Gim Hee Lee</a>
                <br>
                <em>Neural Information Processing Systems (<strong>NeurIPS</strong>)</em>, 2023
                <br>
                (<sup>&#x2709</sup> Corresponding author)
                <br>
                <a href="https://arxiv.org/abs/2307.09112">Paper</a>
                /
                <a href="https://numcc.github.io/">Project Page</a>
                /
                <a href="https://github.com/sail-sg/numcc">Code</a> 
                /
                <a href="https://slideslive.com/39008327/numcc-multiview-compressive-coding-with-neighborhood-decoder-and-repulsive-udf?ref=speaker-29421">Video</a> 
                <p>An efficient architecture and representation for single-view 3D reconstruction.</p>
              </td>
            </tr>

              <!-- 3DV NeuralBlox -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div>
                    <!-- <div class="two" id='tog23sewformer_image'>
                      <img src='images/tog23sewformer_after.mp4' width="160">
                    </div> -->
                    <img src='images/neuralblox.png' width="200">
                  </div>
                </td>
                <td width="90%" valign="middle">
                  <a href="https://github.com/ethz-asl/neuralblox">
                    <papertitle>NeuralBlox: Real-Time Neural Representation Fusion for Robust Volumetric Mapping</papertitle>
                  </a>
                  <br>
                  <strong>Stefan Lionar*</strong>, <a href="https://schmluk.github.io/">Lukas Schmid*</a>, <a href="https://scholar.google.com/citations?user=aOns5HQAAAAJ&hl=en">Cesar Cadena</a>, <a href="https://scholar.google.com/citations?user=MDIyLnwAAAAJ&hl=en">Roland Siegwart</a>, <a href="https://scholar.google.com/citations?user=QZKCzOQAAAAJ&hl=en">Andrei Cramariuc</a>
                  <br>
                  <em>International Conference on 3D Vision (<strong>3DV</strong>)</em>, 2021
                  <br>
                  (*Equal contribution)
                  <br>
                  <a href="https://arxiv.org/abs/2110.09415">Paper</a>
                  /
                  <a href="https://github.com/ethz-asl/neuralblox">Code</a> <a class="more-link" href="https://github.com/ethz-asl/neuralblox" target="_blank"><img alt="GitHub stars" align="right"
                    src="https://img.shields.io/github/stars/ethz-asl/neuralblox?style=social"></a>

                  <p>A robust incremental volumetric mapping framework using neural representation.</p>
                </td>
              </tr>

              
              <!-- WACV DPConvONet -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div>
                    <!-- <div class="two" id='tog23sewformer_image'>
                      <img src='images/tog23sewformer_after.mp4' width="160">
                    </div> -->
                    <img src='images/dp-con.png' width="200">
                  </div>
                </td>
                <td width="90%" valign="middle">
                  <a href="https://github.com/dsvilarkovic/dynamic_plane_convolutional_onet">
                    <papertitle>Dynamic Plane Convolutional Occupancy Networks</papertitle>
                  </a>
                  <br>
                  <strong>Stefan Lionar*</strong>, <a href="https://github.com/daniil-777">Daniil Emtsev*</a>, <a href="https://dsvilarkovic.github.io/">Dusan Svilarkovic*</a>, <a href="https://pengsongyou.github.io/">Songyou Peng</a>
                  <br>
                  <em>Winter Conference on Applications of Computer Vision (<strong>WACV</strong>)</em>, 2021
                  <br>
                  (*Equal contribution)
                  <br>
                  <a href="https://arxiv.org/abs/2011.05813">Paper</a>
                  /
                  <a href="https://github.com/dsvilarkovic/dynamic_plane_convolutional_onet">Code</a> 
                  /
                <a href="https://www.youtube.com/watch?v=Upzh5xCIPu0">Video</a> 

                  <p>We propose implicit representation using multiple 2D planes for accurate 3D surface reconstruction from point cloud.</p>
                </td>
              </tr>

             

            </tbody>
          </table>



            <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Other Selected Projects</heading>
                  
                </td>
              </tr>
            </tbody>
          </table>


          <table
            style="width:100%;border:1px;border-spacing:1px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>



              <!-- BioMind -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div>
                    <!-- <div class="two" id='tog23sewformer_image'>
                      <img src='images/tog23sewformer_after.mp4' width="160">
                    </div> -->
                  <!-- Video demo -->

                <img src='images/biomind.png' width="200">
                  </div>
                </td>
                <td width="90%" valign="middle">
                  <a href="https://biomind.ai/product">
                    <papertitle>2.5D U-Net for Fast and Accurate Brain Tumor Segmentation</papertitle>
                  </a>
                  <br>
                  <a href="https://biomind.ai/product">BioMind</a>
                  <br>
                  2022
                  <em></em>
                  <br>
                  <p></p>
                </td>
              </tr>


                <!-- Duckietown-->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div>
                    <!-- <div class="two" id='tog23sewformer_image'>
                      <img src='images/tog23sewformer_after.mp4' width="160">
                    </div> -->
                  <!-- Video demo -->

              <video width="200" height="auto" autoplay muted loop playsinline style="display:block;">
                <source src="video/duckietown_240.mp4" type="video/mp4">
              </video>
                  </div>
                </td>
                <td width="90%" valign="middle">
                  <a href="https://duckietown.com/yolo-based-robust-object-detection/">
                    <papertitle>Robust Object Detection in Duckietown</papertitle>
                  </a>
                  <br>
                  <a href=https://www.linkedin.com/in/maximilian-stoelzle/>Maximilian Stölzle</a>,  <strong>Stefan Lionar</strong>
                  <br>
                  <em><a href="https://duckietown.com/yolo-based-robust-object-detection/">Duckietown class</a> at ETH Zurich</em>, 2019
                  <em></em>
                  <br>
                  <p>Explore various data augmentation, design safety-oriented loss function, and integrate Google Coral Edge TPU for real-time inference.</p>
                </td>
              </tr>


          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:center;font-size:small;">
                    Website template is taken from <a href="https://github.com/jonbarron/jonbarron_website">here</a>
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
        </td>
      </tr>
  </table>
</body>

</html>